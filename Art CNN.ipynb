{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Neural Networks & Art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import os\n",
    "import zipfile\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip data file\n",
    "path = \"/Users/jillianbrady/Desktop/Core/Final/painter-by-numbers.zip\"\n",
    "directory_to_extract_to = \"/Users/jillianbrady/Desktop/Core/Final/FData\"\n",
    "with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(directory_to_extract_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip individual datasets within data file\n",
    "training_files = [\"train_1\", \"train_2\", \"train_3\", \"train_4\", \"train_5\", \"train_6\", \"train_7\", \"train_8\", \"train_9\", \"train\", \"test\"]\n",
    "\n",
    "for zfile in training_files:\n",
    "    f_path = \"/Users/jillianbrady/Desktop/Core/Final/FData/\" + zfile + \".zip\"\n",
    "    save_to = \"/Users/jillianbrady/Desktop/Core/Final/FData\"\n",
    "    with zipfile.ZipFile(f_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(save_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images to 200 x 200 x 3\n",
    "fpath = \"/Users/jillianbrady/Desktop/Core/Final/FData/Picasso/\"\n",
    "yes_path = fpath + \"YES_original/\"\n",
    "no_path = fpath + \"NO_original\"\n",
    "\n",
    "for item in os.listdir(yes_path):\n",
    "    if item != \".DS_Store\":\n",
    "        with open ((yes_path + '/' + item), 'rb') as file:\n",
    "            im = Image.open(io.BytesIO(file.read()))\n",
    "        imResize = im.resize((200,200), Image.ANTIALIAS)\n",
    "        if np.array(imResize).shape == (200,200,3):\n",
    "            imResize.save(fpath + \"YES/\" + item[:-4] + ' resized.jpg', 'JPEG', quality=90)\n",
    "        \n",
    "for item in os.listdir(no_path):\n",
    "    if item != \".DS_Store\":\n",
    "        with open ((no_path + '/' + item), 'rb') as file:\n",
    "            im = Image.open(io.BytesIO(file.read()))\n",
    "            if item == \"121.jpg\" or item == \"195.jpg\" or item == \"196.jpg\":\n",
    "                im = im.convert('RGB')\n",
    "        imResize = im.resize((200,200), Image.ANTIALIAS)\n",
    "        if np.array(imResize).shape == (200,200,3):\n",
    "            imResize.save(fpath + \"NO/\" + item[:-4] + ' resized.jpg', 'JPEG', quality=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "# Cropped images\n",
    "for item in os.listdir(yes_path):\n",
    "    if item != \".DS_Store\":\n",
    "        with open ((yes_path + '/' + item), 'rb') as file:\n",
    "            im = Image.open(io.BytesIO(file.read()))\n",
    "            \n",
    "        width, height = im.size\n",
    "        if width > height:\n",
    "            short = height\n",
    "        else:\n",
    "            short = width\n",
    "        imCrop = im.crop((0, 0, short, short))\n",
    "        \n",
    "        imResize = imCrop.resize((200,200), Image.ANTIALIAS)\n",
    "        if np.array(imResize).shape == (200,200,3):\n",
    "            imResize.save(fpath + \"YES/\" + item[:-4] + ' resized1.jpg', 'JPEG', quality=90)\n",
    "\n",
    "# Cropped & rotated images\n",
    "for item in os.listdir(yes_path):\n",
    "    if item != \".DS_Store\":\n",
    "        with open ((yes_path + '/' + item), 'rb') as file:\n",
    "            im = Image.open(io.BytesIO(file.read()))\n",
    "            \n",
    "        width, height = im.size\n",
    "        if width > height:\n",
    "            imCrop = im.crop((width-height, 0, height, width))\n",
    "        elif height > width:\n",
    "            imCrop = im.crop((0, height-width, width, height))\n",
    "        else:\n",
    "            imCrop = im\n",
    "        imCrop = imCrop.rotate(90)\n",
    "        \n",
    "        imResize = imCrop.resize((200,200), Image.ANTIALIAS)\n",
    "        if np.array(imResize).shape == (200,200,3):\n",
    "            imResize.save(fpath + \"YES/\" + item[:-4] + ' resized2.jpg', 'JPEG', quality=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add images to X and labels to y\n",
    "y_path = fpath + \"YES\"\n",
    "n_path = fpath + \"NO\"\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for f in os.listdir(y_path):\n",
    "    if f != \".DS_Store\":\n",
    "        with open ((y_path + \"/\" + f), 'rb') as file:\n",
    "            im = Image.open(io.BytesIO(file.read()))\n",
    "        im = np.array(im)\n",
    "        X.append(im)\n",
    "        # 1 = images that are by Picasso\n",
    "        y.append(1)\n",
    "\n",
    "for f in os.listdir(n_path):\n",
    "    if f != \".DS_Store\":\n",
    "        with open ((n_path + \"/\" + f), 'rb') as file:\n",
    "            im = Image.open(io.BytesIO(file.read()))\n",
    "        im = np.array(im)\n",
    "        X.append(im)\n",
    "        # 0 = images not by Picasso\n",
    "        y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into train and test sets\n",
    "X = np.array(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.05, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format data for CNN\n",
    "img_rows, img_cols = 200, 200\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: ls It a Picasso?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2926 samples, validate on 155 samples\n",
      "Epoch 1/5\n",
      "2926/2926 [==============================] - 7s 2ms/step - loss: 0.6073 - accuracy: 0.6753 - val_loss: 0.5570 - val_accuracy: 0.6968\n",
      "Epoch 2/5\n",
      "2926/2926 [==============================] - 7s 2ms/step - loss: 0.5416 - accuracy: 0.7280 - val_loss: 0.5055 - val_accuracy: 0.7548\n",
      "Epoch 3/5\n",
      "2926/2926 [==============================] - 6s 2ms/step - loss: 0.5124 - accuracy: 0.7567 - val_loss: 0.4990 - val_accuracy: 0.7355\n",
      "Epoch 4/5\n",
      "2926/2926 [==============================] - 7s 2ms/step - loss: 0.4909 - accuracy: 0.7703 - val_loss: 0.4500 - val_accuracy: 0.7484\n",
      "Epoch 5/5\n",
      "2926/2926 [==============================] - 6s 2ms/step - loss: 0.4761 - accuracy: 0.7703 - val_loss: 0.4611 - val_accuracy: 0.7613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a45ee2f60>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, activation='relu', kernel_size=3, strides=(3, 3), input_shape=(200, 200, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=32, activation='relu',kernel_size=3, strides=(3, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, activation='relu', kernel_size=3, strides=(3, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=16,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "pre_round = []\n",
    "for val in predictions:\n",
    "    if val < .5:\n",
    "        pre_round.append(0)\n",
    "    else:\n",
    "        pre_round.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t0.7612903225806451\n",
      "% False Negatives:\t0.43243243243243246\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "incorrect = 0\n",
    "false_positive = 0\n",
    "false_negative = 0\n",
    "for x in range(len(y_test)):\n",
    "    if y_test[x] == pre_round[x]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "        if y_test[x] == 1:\n",
    "            false_negative+=1\n",
    "        else:\n",
    "            false_positive+=1\n",
    "            \n",
    "print(\"Accuracy:\\t\\t\" + str(correct/len(y_test)))\n",
    "print(\"% False Negatives:\\t\" + str(false_negative/incorrect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The model predicts whether a work of art is by Picasso with **76% accuracy**.\n",
    "* In its inaccurate predictions, there is a **balance between false negatives and false positives**.\n",
    ">\n",
    ">This means that the model doesn't always predict \"Yes\" because there are more works by Picasso in the dataset, and doesn't always predict \"No\" because there are far fewer works by Picasso in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting images from directory\n",
    "ty_path = fpath + \"test_yes\"\n",
    "tn_path = fpath + \"test_no\"\n",
    "ty = []\n",
    "tn = []\n",
    "\n",
    "for f in os.listdir(ty_path):\n",
    "    if f != \".DS_Store\":\n",
    "        with open ((ty_path + \"/\" + f), 'rb') as file:\n",
    "            im = Image.open(io.BytesIO(file.read()))\n",
    "        im = np.array(im)\n",
    "        ty.append(im)\n",
    "\n",
    "for f in os.listdir(tn_path):\n",
    "    if f != \".DS_Store\":\n",
    "        with open ((tn_path + \"/\" + f), 'rb') as file:\n",
    "            im = Image.open(io.BytesIO(file.read()))\n",
    "        im = np.array(im)\n",
    "        tn.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting data for CNN\n",
    "img_rows, img_cols = 200, 200\n",
    "\n",
    "ty = np.array(ty)\n",
    "tn = np.array(tn)\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    ty = ty.reshape(ty.shape[0], 3, img_rows, img_cols)\n",
    "    tn = tn.reshape(tn.shape[0], 3, img_rows, img_cols)\n",
    "else:\n",
    "    ty = ty.reshape(ty.shape[0], img_rows, img_cols, 3)\n",
    "    tn = tn.reshape(tn.shape[0], img_rows, img_cols, 3)\n",
    "\n",
    "ty = ty.astype('float32')\n",
    "tn = tn.astype('float32')\n",
    "ty /= 255\n",
    "tn /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on new test datasets\n",
    "all_pred = model.predict(ty)\n",
    "none_pred = model.predict(tn)\n",
    "\n",
    "all_rounded = []\n",
    "none_rounded = []\n",
    "for pred in all_pred:\n",
    "    if pred < .5:\n",
    "        all_rounded.append(0)\n",
    "    else:\n",
    "        all_rounded.append(1)\n",
    "for pred in none_pred:\n",
    "    if pred < .5:\n",
    "        none_rounded.append(0)\n",
    "    else:\n",
    "        none_rounded.append(1)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(all_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model identifies 5 works by Picasso that it has never seen before correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(none_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of 10 works that are not by Picasso that the model has never seen before, it predicts that 3 are by Picasso and that 12 are not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
